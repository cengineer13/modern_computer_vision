{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f35a0f",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/cengineer13/modern_computer_vision/main/LOGO.png)\n",
    "# **Implement the Tilt Shift Effect**\n",
    "\n",
    "- In this lesson we'll go through some code that generates our Titl Shift effect on our sample images\n",
    "\n",
    "Source - https://github.com/powersj/tilt-shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d246cd",
   "metadata": {},
   "source": [
    "## 1. **Our Functions to implement Tilt Shift**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdfe2a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\"\"\"Script to blend two images.\"\"\"\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import shutil\n",
    "\n",
    "\n",
    "def generating_kernel(parameter):\n",
    "    \"\"\" Return a 5x5 generating kernel based on an input parameter.\n",
    "\n",
    "    Note: This function is provided for you, do not change it.\n",
    "\n",
    "    Args:\n",
    "    parameter (float): Range of value: [0, 1].\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 5x5 kernel.\n",
    "\n",
    "    \"\"\"\n",
    "    kernel = np.array([0.25 - parameter / 2.0, 0.25, parameter,\n",
    "                       0.25, 0.25 - parameter / 2.0])\n",
    "    return np.outer(kernel, kernel)\n",
    "\n",
    "\n",
    "def reduce_img(image):\n",
    "    \"\"\" Convolve the input image with a generating kernel of parameter of 0.4\n",
    "    and then reduce its width and height by two.\n",
    "\n",
    "    You can use any / all functions to convolve and reduce the image, although\n",
    "    the lectures have recommended methods that we advise since there are a lot\n",
    "    of pieces to this assignment that need to work 'just right'.\n",
    "\n",
    "    Args:\n",
    "    image (numpy.ndarray): a grayscale image of shape (r, c)\n",
    "\n",
    "    Returns:\n",
    "    output (numpy.ndarray): an image of shape (ceil(r/2), ceil(c/2))\n",
    "      For instance, if the input is 5x7, the output will be 3x4.\n",
    "\n",
    "    \"\"\"\n",
    "    # per the instructions, use 0.4 for the kernel generation\n",
    "    kernel = generating_kernel(0.4)\n",
    "\n",
    "    # use convolve2d with the image and kernel sent in\n",
    "    output = scipy.signal.convolve2d(image, kernel, 'same')\n",
    "\n",
    "    # return every other line and row\n",
    "    return output[:output.shape[0]:2, :output.shape[1]:2]\n",
    "\n",
    "\n",
    "def expand(image):\n",
    "    \"\"\" Expand the image to double the size and then convolve it with a\n",
    "    generating kernel with a parameter of 0.4.\n",
    "\n",
    "    You should upsample the image, and then convolve it with a generating\n",
    "    kernel of a = 0.4.\n",
    "\n",
    "    Finally, multiply your output image by a factor of 4 in order to scale it\n",
    "    back up. If you do not do this (and I recommend you try it out without\n",
    "    that) you will see that your images darken as you apply the convolution.\n",
    "    Please explain why this happens in your submission PDF.\n",
    "\n",
    "    Please consult the lectures and readme for a more in-depth discussion of\n",
    "    how to tackle the expand function.\n",
    "\n",
    "    You can use any / all functions to convolve and reduce the image, although\n",
    "    the lectures have recommended methods that we advise since there are a lot\n",
    "    of pieces to this assignment that need to work 'just right'.\n",
    "\n",
    "    Args:\n",
    "    image (numpy.ndarray): a grayscale image of shape (r, c)\n",
    "\n",
    "    Returns:\n",
    "    output (numpy.ndarray): an image of shape (2*r, 2*c)\n",
    "    \"\"\"\n",
    "    # per the instructions, use 0.4 for the kernel generation\n",
    "    kernel = generating_kernel(0.4)\n",
    "\n",
    "    # make a new array double the size, assign initial values\n",
    "    output = np.zeros((image.shape[0] * 2, image.shape[1] * 2))\n",
    "    output[:output.shape[0]:2, :output.shape[1]:2] = image\n",
    "\n",
    "    # use convolve2d to fill in rest\n",
    "    # multiply by 4 per instructions to scale back up\n",
    "    output = scipy.signal.convolve2d(output, kernel, 'same') * 4\n",
    "    return output\n",
    "\n",
    "\n",
    "def gauss_pyramid(image, levels):\n",
    "    \"\"\" Construct a pyramid from the image by reducing it by the number of\n",
    "    levels passed in by the input.\n",
    "\n",
    "    Note: You need to use your reduce function in this function to generate the\n",
    "    output.\n",
    "\n",
    "    Args:\n",
    "      image (numpy.ndarray): A grayscale image of dimension (r,c) and dtype\n",
    "      float.\n",
    "      levels (uint8): A positive integer that specifies the number of\n",
    "                    reductions you should do. So, if levels = 0, you should\n",
    "                    return a list containing just the input image. If\n",
    "                    levels = 1, you should do one reduction.\n",
    "                    len(output) = levels + 1\n",
    "\n",
    "    Returns:\n",
    "      output (list): A list of arrays of dtype np.float. The first element of\n",
    "                the list (output[0]) is layer 0 of the pyramid (the image\n",
    "                itself). output[1] is layer 1 of the pyramid (image reduced\n",
    "                once), etc. We have already included the original image in\n",
    "                the output array for you. The arrays are of type numpy.ndarray.\n",
    "\n",
    "    Consult the lecture and README for more details about Gaussian Pyramids.\n",
    "    \"\"\"\n",
    "    output = [image]\n",
    "    for level in range(levels):\n",
    "        output.append(reduce_img(output[level]))\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def lapl_pyramid(gauss_pyr):\n",
    "    \"\"\" Construct a Laplacian pyramid from the Gaussian pyramid, of height\n",
    "    levels.\n",
    "\n",
    "    Note: You must use your expand function in this function to generate the\n",
    "    output. The Gaussian Pyramid that is passed in is the output of your\n",
    "    gauss_pyramid function.\n",
    "\n",
    "    Args:\n",
    "      gauss_pyr (list): A Gaussian Pyramid as returned by your gauss_pyramid\n",
    "                     function. It is a list of numpy.ndarray items.\n",
    "\n",
    "    Returns:\n",
    "      output (list): A Laplacian pyramid of the same size as gauss_pyr. This\n",
    "                   pyramid should be represented in the same way as guassPyr,\n",
    "                   as a list of arrays. Every element of the list now\n",
    "                   corresponds to a layer of the Laplacian pyramid, containing\n",
    "                   the difference between two layers of the Gaussian pyramid.\n",
    "\n",
    "           output[k] = gauss_pyr[k] - expand(gauss_pyr[k + 1])\n",
    "\n",
    "           Note: The last element of output should be identical to the last\n",
    "           layer of the input pyramid since it cannot be subtracted anymore.\n",
    "\n",
    "    Note: Sometimes the size of the expanded image will be larger than the\n",
    "    given layer. You should crop the expanded image to match in shape with\n",
    "    the given layer.\n",
    "\n",
    "    For example, if my layer is of size 5x7, reducing and expanding will result\n",
    "    in an image of size 6x8. In this case, crop the expanded layer to 5x7.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    # look over the lists, but ignore the last element since it cannot be\n",
    "    # subtracted\n",
    "    for image1, image2 in zip(gauss_pyr[:-1], gauss_pyr[1:]):\n",
    "        # add in the subtracted difference\n",
    "        # expand and bind the 2nd image based on the dimentions of the first\n",
    "        output.append(\n",
    "            image1 - expand(image2)[:image1.shape[0], :image1.shape[1]])\n",
    "\n",
    "    # now add the last item back in\n",
    "    output.append(gauss_pyr[-1])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def blend(lapl_pyr_white, lapl_pyr_black, gauss_pyr_mask):\n",
    "    \"\"\" Blend the two Laplacian pyramids by weighting them according to the\n",
    "    Gaussian mask.\n",
    "\n",
    "    Args:\n",
    "      lapl_pyr_white (list): A Laplacian pyramid of one image, as constructed\n",
    "                        by your lapl_pyramid function.\n",
    "\n",
    "      lapl_pyr_black (list): A Laplacian pyramid of another image, as\n",
    "                        constructed by your lapl_pyramid function.\n",
    "\n",
    "      gauss_pyr_mask (list): A Gaussian pyramid of the mask. Each value is in\n",
    "                         the range of [0, 1].\n",
    "\n",
    "    The pyramids will have the same number of levels. Furthermore, each layer\n",
    "    is guaranteed to have the same shape as previous levels.\n",
    "\n",
    "    You should return a Laplacian pyramid that is of the same dimensions as the\n",
    "    input pyramids. Every layer should be an alpha blend of the corresponding\n",
    "    layers of the input pyramids, weighted by the Gaussian mask. This means the\n",
    "    following computation for each layer of the pyramid:\n",
    "      output[i, j] = current_mask[i, j] * white_image[i, j] +\n",
    "                   (1 - current_mask[i, j]) * black_image[i, j]\n",
    "    Therefore:\n",
    "      Pixels where current_mask == 1 should be taken completely from the white\n",
    "      image.\n",
    "      Pixels where current_mask == 0 should be taken completely from the black\n",
    "      image.\n",
    "\n",
    "    Note: current_mask, white_image, and black_image are variables that refer\n",
    "    to the image in the current layer we are looking at. You do this\n",
    "    computation for every layer of the pyramid.\n",
    "    \"\"\"\n",
    "    blended_pyr = []\n",
    "    for lapl_white, lapl_black, gauss_mask in \\\n",
    "            zip(lapl_pyr_white, lapl_pyr_black, gauss_pyr_mask):\n",
    "        blended_pyr.append(gauss_mask * lapl_white +\n",
    "                           (1 - gauss_mask) * lapl_black)\n",
    "\n",
    "    return blended_pyr\n",
    "\n",
    "\n",
    "def collapse(pyramid):\n",
    "    \"\"\" Collapse an input pyramid.\n",
    "\n",
    "    Args:\n",
    "      pyramid (list): A list of numpy.ndarray images. You can assume the input\n",
    "            is taken from blend() or lapl_pyramid().\n",
    "\n",
    "    Returns:\n",
    "      output(numpy.ndarray): An image of the same shape as the base layer of\n",
    "            the pyramid and dtype float.\n",
    "\n",
    "    Approach this problem as follows, start at the smallest layer of the\n",
    "    pyramid. Expand the smallest layer, and add it to the second to smallest\n",
    "    layer. Then, expand the second to smallest layer, and continue the process\n",
    "    until you are at the largest image. This is your result.\n",
    "\n",
    "    Note: sometimes expand will return an image that is larger than the next\n",
    "    layer. In this case, you should crop the expanded image down to the size of\n",
    "    the next layer. Look into numpy slicing / read our README to do this\n",
    "    easily.\n",
    "\n",
    "    For example, expanding a layer of size 3x4 will result in an image of size\n",
    "    6x8. If the next layer is of size 5x7, crop the expanded image to size 5x7.\n",
    "    \"\"\"\n",
    "    output = pyramid[-1]\n",
    "    for image in reversed(pyramid[:-1]):\n",
    "        output = image + expand(output)[:image.shape[0], :image.shape[1]]\n",
    "    return output\n",
    "\n",
    "\n",
    "def run_blend(black_image, white_image, mask):\n",
    "    \"\"\" This function administrates the blending of the two images according to\n",
    "    mask.\n",
    "\n",
    "    Assume all images are float dtype, and return a float dtype.\n",
    "    \"\"\"\n",
    "\n",
    "    # Automatically figure out the size\n",
    "    min_size = min(black_image.shape)\n",
    "    # at least 16x16 at the highest level.\n",
    "    depth = int(math.floor(math.log(min_size, 2))) - 4\n",
    "\n",
    "    gauss_pyr_mask = gauss_pyramid(mask, depth)\n",
    "    gauss_pyr_black = gauss_pyramid(black_image, depth)\n",
    "    gauss_pyr_white = gauss_pyramid(white_image, depth)\n",
    "\n",
    "    lapl_pyr_black = lapl_pyramid(gauss_pyr_black)\n",
    "    lapl_pyr_white = lapl_pyramid(gauss_pyr_white)\n",
    "\n",
    "    outpyr = blend(lapl_pyr_white, lapl_pyr_black, gauss_pyr_mask)\n",
    "    outimg = collapse(outpyr)\n",
    "\n",
    "    # blending sometimes results in slightly out of bound numbers.\n",
    "    outimg[outimg < 0] = 0\n",
    "    outimg[outimg > 255] = 255\n",
    "    outimg = outimg.astype(np.uint8)\n",
    "\n",
    "    return outimg\n",
    "\n",
    "\n",
    "def get_images(sourcefolder):\n",
    "    \"\"\"Rewritten function to collect the three images from three folders.\"\"\"\n",
    "    filenames = os.listdir(sourcefolder)\n",
    "    print(filenames)\n",
    "    for photo in filenames:\n",
    "        black_img = cv2.imread('tilt-shift/orginal'+photo)\n",
    "        white_img = cv2.imread('images/blur/' + photo)\n",
    "        mask_img = cv2.imread('images/mask/' + photo)\n",
    "\n",
    "        if mask_img is None:\n",
    "            print('Oops! There is no mask of image: ', photo)\n",
    "            continue\n",
    "        if white_img is None:\n",
    "            print('Oops! There is no blurred version of image: ', photo)\n",
    "            continue\n",
    "\n",
    "        assert black_img.shape == white_img.shape, \\\n",
    "            \"Error - the sizes of orignal and blur are not equal\"\n",
    "\n",
    "        assert black_img.shape == mask_img.shape, \\\n",
    "            \"Error - the sizes of the original and the mask are not equal\"\n",
    "\n",
    "        print(photo)\n",
    "        yield photo, white_img, black_img, mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e55a3fac",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Datasets/images/tilt-shift/orginal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...[DONE]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(outfolder)\n\u001b[0;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(outfolder)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m photo, white_img, black_img, mask_img \u001b[38;5;129;01min\u001b[39;00m get_images(sourcefolder):\n\u001b[0;32m     12\u001b[0m     imshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Image\u001b[39m\u001b[38;5;124m\"\u001b[39m, black_img)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...applying blending\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mget_images\u001b[1;34m(sourcefolder)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_images\u001b[39m(sourcefolder):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;124;03m\"\"\"Rewritten function to collect the three images from three folders.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     filenames \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msourcefolder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28mprint\u001b[39m(filenames)\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m photo \u001b[38;5;129;01min\u001b[39;00m filenames:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Datasets/images/tilt-shift/orginal'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Given the two images, blend them according to the mask.\"\"\"\n",
    "\n",
    "    sourcefolder = 'Datasets/images/tilt-shift/orginal'\n",
    "    outfolder = 'Datasets/images/tilt-shift/output'\n",
    "\n",
    "    if os.path.isdir(outfolder):\n",
    "        shutil.rmtree(outfolder)\n",
    "    os.mkdir(outfolder)\n",
    "    \n",
    "    for photo, white_img, black_img, mask_img in get_images(sourcefolder):\n",
    "        imshow(\"Original Image\", black_img)\n",
    "        print(\"...applying blending\")\n",
    "        black_img = black_img.astype(float)\n",
    "        white_img = white_img.astype(float)\n",
    "        mask_img = mask_img.astype(float) / 255\n",
    "\n",
    "        out_layers = []\n",
    "        for channel in range(3):\n",
    "            outimg = run_blend(black_img[:, :, channel],\n",
    "                               white_img[:, :, channel],\n",
    "                               mask_img[:, :, channel])\n",
    "            out_layers.append(outimg)\n",
    "\n",
    "        outimg = cv2.merge(out_layers)\n",
    "        cv2.imwrite(os.path.join(outfolder, photo), outimg)\n",
    "        imshow(\"Tilt Shift Effect\", outimg)\n",
    "        print('...[DONE]')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "201245ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boat.jpg\n",
      "city.jpg\n",
      "mask\n",
      "original\n",
      "output\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir('Datasets/images/tilt-shift') \n",
    "\n",
    "for photo in filenames:\n",
    "    print(photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93969f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fbee772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\01.PROJECTS\\\\2022 MODERN COMPUTER VISION\\\\2 OpenCV chapter'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "710c8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(my_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a051105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '1. Getting Started - Loading, Displaying, Saving and Dimensions.html',\n",
       " '1. Getting Started - Loading, Displaying, Saving and Dimensions.ipynb',\n",
       " '10. Dilation, Erosion and Edge Detection.html',\n",
       " '10. Dilation, Erosion and Edge Detection.ipynb',\n",
       " '11. Contours - Drawing, Hierarchy and Modes.html',\n",
       " '11. Contours - Drawing, Hierarchy and Modes.ipynb',\n",
       " '12. Contour sorting, Moments, Convex, Contour matching.html',\n",
       " '12. Contour sorting, Moments, Convex, Contour matching.ipynb',\n",
       " '13. Hough Line, Hough Circle and Blob Detection.html',\n",
       " '13. Hough Line, Hough Circle and Blob Detection.ipynb',\n",
       " '14. Counting Circles, Ellipses with Blob parameterizations.html',\n",
       " '14. Counting Circles, Ellipses with Blob parameterizations.ipynb',\n",
       " '14_1 Template matching .html',\n",
       " '14_1 Template matching .ipynb',\n",
       " '15. Corner detections.html',\n",
       " '15. Corner detections.ipynb',\n",
       " '16. Face and Eye Detection with Haar Cascade Classifiers.html',\n",
       " '16. Face and Eye Detection with Haar Cascade Classifiers.ipynb',\n",
       " '17. Vehicle and Pedestrian Detection.html',\n",
       " '17. Vehicle and Pedestrian Detection.ipynb',\n",
       " '18. Perspective Transforms.html',\n",
       " '18. Perspective Transforms.ipynb',\n",
       " '19. K-means (sklearn, openCV) and Histogram.html',\n",
       " '19. K-means (sklearn, openCV) and Histogram.ipynb',\n",
       " '2. Grayscaling Images.html',\n",
       " '2. Grayscaling Images.ipynb',\n",
       " '20. Comparing Images MSE and Skimage Structual Similarity.html',\n",
       " '20. Comparing Images MSE and Skimage Structual Similarity.ipynb',\n",
       " '21. HSV masking, inRange function.html',\n",
       " '21. HSV masking, inRange function.ipynb',\n",
       " '22. Watershed Algorithm  & Pyimagesearch variation traditional segmentation algorithm.html',\n",
       " '22. Watershed Algorithm  & Pyimagesearch variation traditional segmentation algorithm.ipynb',\n",
       " '23. Background and Foreground Subtraction.html',\n",
       " '23. Background and Foreground Subtraction.ipynb',\n",
       " '24. Motion Tracking with Mean Shift and CAMSHIFT.html',\n",
       " '24. Motion Tracking with Mean Shift and CAMSHIFT.ipynb',\n",
       " '25. Object Tracking with Optical Flow.html',\n",
       " '25. Object Tracking with Optical Flow.ipynb',\n",
       " '26. Simple Object Tracking by Color.html',\n",
       " '26. Simple Object Tracking by Color.ipynb',\n",
       " '27_Facial_Landmark_Detection_with_Dlib.html',\n",
       " '27_Facial_Landmark_Detection_with_Dlib.ipynb',\n",
       " '28_Face_Swapping_with_Dlib.html',\n",
       " '28_Face_Swapping_with_Dlib.ipynb',\n",
       " '29. Tilt Shift Effects.ipynb',\n",
       " '3. Color Spaces (RGB and HSV).html',\n",
       " '3. Color Spaces (RGB and HSV).ipynb',\n",
       " '4. Drawing on Images (Shapes and Texts).html',\n",
       " '4. Drawing on Images (Shapes and Texts).ipynb',\n",
       " '5. Transformations - Translations and Rotations.html',\n",
       " '5. Transformations - Translations and Rotations.ipynb',\n",
       " \"6-1 cv2 resize interpolation methods - Chadrick's Blog.pdf\",\n",
       " '6. Scaling, Re-sizing, Interpolations and Cropping.html',\n",
       " '6.Scaling, Re-sizing, Interpolations and Cropping.ipynb',\n",
       " '7. Arithmetic and Bitwise Operations (Increase decrease brightness).html',\n",
       " '7. Arithmetic and Bitwise Operations (Increase decrease brightness).ipynb',\n",
       " '8. Filtering, Blurring and Sharpening Images.html',\n",
       " '8. Filtering, Blurring and Sharpening Images.ipynb',\n",
       " '9. Thresholding,  Adaptive Thresholding.html',\n",
       " '9. Thresholding,  Adaptive Thresholding.ipynb',\n",
       " 'car_tracking_cam_shift.avi',\n",
       " 'Datasets',\n",
       " 'optical_flow_walking.avi',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d9ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
